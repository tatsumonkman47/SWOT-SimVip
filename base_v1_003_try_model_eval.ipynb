{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "173ab067-4338-4798-a75f-b7a93076be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import zarr\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "from hydra import main, initialize, initialize_config_dir\n",
    "from hydra.utils import instantiate\n",
    "from pathlib import Path\n",
    "\n",
    "# Append model path dynamically (could also be in config)\n",
    "sys.path.append('/home/tm3076/projects/NYU_SWOT_project/Inpainting_Pytorch_gen/SWOT-inpainting-DL/src')\n",
    "import simvip_model\n",
    "import data_loaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c145e53-a4b6-419a-84b3-659214b71ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bbf04a1-95e2-4998-89d2-ce4d8cefb63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "data_loaders = reload(data_loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca69c2-bb48-4b1f-a097-d2e7544e898d",
   "metadata": {},
   "source": [
    "# Test model on cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b593e20-ce88-41c0-9bea-b0dad7f92412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute loss with optional masking and per-data-point normalization\n",
    "def compute_loss(model,batch,mode,alpha0,alpha1,alpha2,device,masked_loss=False,):\n",
    "    mse = lambda a, b: (a - b) ** 2\n",
    "    def grad2d(u):\n",
    "        dx = u[..., :, 1:] - u[..., :, :-1]\n",
    "        dy = u[..., 1:, :] - u[..., :-1, :]\n",
    "        return dx, dy\n",
    "    def grad2d_second(u):\n",
    "        dxx = u[..., :, 2:] - 2 * u[..., :, 1:-1] + u[..., :, :-2]\n",
    "        dyy = u[..., 2:, :] - 2 * u[..., 1:-1, :] + u[..., :-2, :]\n",
    "        return dxx, dyy\n",
    "    if mode == 'train':\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "        \n",
    "    x, y, _ = batch\n",
    "    x = x.to(device).float()\n",
    "    y = y.to(device).float()\n",
    "    y_hat = model(x)\n",
    "    \n",
    "    if masked_loss:\n",
    "        # mask == 1 where y is not zero\n",
    "        mask = (y != 0).float()\n",
    "        # Main loss only over unmasked elements\n",
    "        per_element_loss = mse(y, y_hat) * mask\n",
    "        loss = per_element_loss.sum() / mask.sum().clamp_min(1.0)\n",
    "        # Gradients: mask central pixels to avoid border artifacts\n",
    "        central_mask_x = (mask[..., :, 1:] * mask[..., :, :-1])\n",
    "        central_mask_y = (mask[..., 1:, :] * mask[..., :-1, :])\n",
    "        dx_y, dy_y = grad2d(y)\n",
    "        dx_yh, dy_yh = grad2d(y_hat)\n",
    "        grad_loss_x = mse(dx_y, dx_yh) * central_mask_x\n",
    "        grad_loss_y = mse(dy_y, dy_yh) * central_mask_y\n",
    "        loss_grad = (\n",
    "            grad_loss_x.sum() / central_mask_x.sum().clamp_min(1.0)\n",
    "            + grad_loss_y.sum() / central_mask_y.sum().clamp_min(1.0)\n",
    "        )\n",
    "        # Second gradients: mask central pixels\n",
    "        central_mask_xx = (mask[..., :, 2:] * mask[..., :, 1:-1] * mask[..., :, :-2])\n",
    "        central_mask_yy = (mask[..., 2:, :] * mask[..., 1:-1, :] * mask[..., :-2, :])\n",
    "        dxx_y, dyy_y = grad2d_second(y)\n",
    "        dxx_yh, dyy_yh = grad2d_second(y_hat)\n",
    "        grad2_loss_x = mse(dxx_y, dxx_yh) * central_mask_xx\n",
    "        grad2_loss_y = mse(dyy_y, dyy_yh) * central_mask_yy\n",
    "        loss_grad2 = (\n",
    "            grad2_loss_x.sum() / central_mask_xx.sum().clamp_min(1.0)\n",
    "            + grad2_loss_y.sum() / central_mask_yy.sum().clamp_min(1.0)\n",
    "        )\n",
    "    else:\n",
    "        # Unmasked case: treat all pixels as valid\n",
    "        valid_count = torch.numel(y)\n",
    "        per_element_loss = mse(y, y_hat)\n",
    "        loss = per_element_loss.sum() / valid_count\n",
    "        dx_y, dy_y = grad2d(y)\n",
    "        dx_yh, dy_yh = grad2d(y_hat)\n",
    "        grad_loss_x = mse(dx_y, dx_yh)\n",
    "        grad_loss_y = mse(dy_y, dy_yh)\n",
    "\n",
    "        # For gradients, the counts are smaller because of the shifts:\n",
    "        count_dx = dx_y.numel()\n",
    "        count_dy = dy_y.numel()\n",
    "        loss_grad = (\n",
    "            grad_loss_x.sum() / count_dx\n",
    "            + grad_loss_y.sum() / count_dy\n",
    "        )\n",
    "        dxx_y, dyy_y = grad2d_second(y)\n",
    "        dxx_yh, dyy_yh = grad2d_second(y_hat)\n",
    "        count_dxx = dxx_y.numel()\n",
    "        count_dyy = dyy_y.numel()\n",
    "        grad2_loss_x = mse(dxx_y, dxx_yh)\n",
    "        grad2_loss_y = mse(dyy_y, dyy_yh)\n",
    "        loss_grad2 = (\n",
    "            grad2_loss_x.sum() / count_dxx\n",
    "            + grad2_loss_y.sum() / count_dyy\n",
    "        )\n",
    "\n",
    "    total_loss = alpha0 * loss + alpha1 * loss_grad + alpha2 * loss_grad2\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84e5875a-c003-49e3-9e79-d637669d1f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    device,\n",
    "    model_name,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    num_epochs,\n",
    "    lr,\n",
    "    alpha0,\n",
    "    alpha1,\n",
    "    alpha2,\n",
    "    masked_loss,\n",
    "    checkpoint_dir=\"checkpoints\",\n",
    "    wandb_config=None\n",
    "):\n",
    "    import wandb\n",
    "\n",
    "    # Create directories\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100,500], gamma=0.1)\n",
    "\n",
    "    # Initialize wandb\n",
    "    if wandb_config:\n",
    "        wandb.init(\n",
    "            project=wandb_config[\"project\"],\n",
    "            name=wandb_config.get(\"run_name\", model_name),\n",
    "            config={\n",
    "                \"lr\": lr,\n",
    "                \"num_epochs\": num_epochs,\n",
    "                \"alpha0\": alpha0,\n",
    "                \"alpha1\": alpha1,\n",
    "                \"alpha2\": alpha2,\n",
    "            }\n",
    "        )\n",
    "        wandb.run.log_code(\".\")\n",
    "        \n",
    "    log_path = f\"logs/{model_name}_log.csv\"\n",
    "    if not os.path.exists(log_path):\n",
    "        with open(log_path,'w',newline='') as f:\n",
    "            csv.writer(f).writerow([\"epoch\",\"train_loss\",\"val_loss\",\"epoch_time_sec\"])\n",
    "    best_val_loss = float(\"inf\")\n",
    "    global_step = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        start_time = time.time()\n",
    "        for batch_idx, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\", leave=False)):\n",
    "            optimizer.zero_grad()\n",
    "            loss = compute_loss(model, batch, 'train', alpha0, alpha1, alpha2, device, masked_loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            # Wandb log per batch\n",
    "            if global_step % 10 == 0:\n",
    "                if wandb_config:\n",
    "                    wandb.log({\n",
    "                        \"train/batch_loss\": loss.item(),\n",
    "                        \"epoch\": epoch + 1,\n",
    "                        \"global_step\": global_step,\n",
    "                        \"learning_rate\": scheduler.get_last_lr()[0],\n",
    "                    })\n",
    "            global_step += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        train_loss = np.mean(train_losses)\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "                val_loss = compute_loss(model, batch, 'val', alpha0, alpha1, alpha2, device, masked_loss)\n",
    "                val_losses.append(val_loss.item())\n",
    "        val_loss = np.mean(val_losses)\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"[{epoch+1}] Train: {train_loss:.4f}  Val: {val_loss:.4f}\")\n",
    "        # Save checkpoint every epoch\n",
    "        checkpoint_data = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"best_val_loss\": best_val_loss,\n",
    "        }\n",
    "        ckpt_filename = f\"{model_name}_checkpoint_{epoch+1}.pt\"\n",
    "        torch.save(checkpoint_data, os.path.join(checkpoint_dir, ckpt_filename))\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), os.path.join(checkpoint_dir, f\"{model_name}_best.pt\"))\n",
    "            print(f\"✅ Best model updated (Val Loss: {best_val_loss:.4f})\")\n",
    "        # Append CSV log\n",
    "        with open(log_path,'a',newline='') as f:\n",
    "            csv.writer(f).writerow([epoch+1, train_loss, val_loss, round(epoch_time,2)])\n",
    "        # Wandb log summary stats per epoch\n",
    "        if wandb_config:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch+1,\n",
    "                \"train/epoch_loss\": train_loss,\n",
    "                \"val/epoch_loss\": val_loss,\n",
    "                \"epoch_time_sec\": epoch_time,\n",
    "            })\n",
    "\n",
    "    # Test\n",
    "    model.eval()\n",
    "    test_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "            test_loss = compute_loss(model, batch, 'test', alpha0, alpha1, alpha2, device, masked_loss)\n",
    "            test_losses.append(test_loss.item())\n",
    "    test_loss = np.mean(test_losses)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    if wandb_config:\n",
    "        wandb.log({\"test_loss\": test_loss})\n",
    "        wandb.finish()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fee286c0-54bc-4f8e-9ba1-6a39099876f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GlobalHydra' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhydra\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initialize, compose\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01momegaconf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OmegaConf\n\u001b[0;32m----> 4\u001b[0m \u001b[43mGlobalHydra\u001b[49m\u001b[38;5;241m.\u001b[39minstance()\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Only initialize Hydra if it's not already initialized\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mglobals\u001b[39m(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_HYDRA_INITIALIZED\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GlobalHydra' is not defined"
     ]
    }
   ],
   "source": [
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Only initialize Hydra if it's not already initialized\n",
    "if not hasattr(globals(), \"_HYDRA_INITIALIZED\"):\n",
    "    initialize(version_base=None, config_path=\"conf\")\n",
    "    _HYDRA_INITIALIZED = True\n",
    "\n",
    "cfg = compose(config_name=\"001_base_config\")\n",
    "print(OmegaConf.to_yaml(cfg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "488f7c4d-6126-459f-9c4c-e1308b0d5a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outdir: ./outputs_SimVip_July_10\n",
      "data:\n",
      "  dataset_path: /home/tm3076/scratch/pytorch_learning_tiles\n",
      "  patch_coords_file: x_y_coordinates_noland.zarr\n",
      "  infields:\n",
      "  - zarr_llc4320_SSH_tiles_4km_filtered\n",
      "  - zarr_llc4320_SST_tiles_4km\n",
      "  outfields:\n",
      "  - zarr_llc4320_SSH_tiles_4km_filtered\n",
      "  in_mask_list:\n",
      "  - nadir\n",
      "  - cloud_rho\n",
      "  out_mask_list:\n",
      "  - swot_central\n",
      "  in_transform_list:\n",
      "  - std_global_mean_ssh_norm\n",
      "  - std_global_mean_sst_norm\n",
      "  out_transform_list:\n",
      "  - std_global_mean_ssh_norm\n",
      "  mean_ssh: 0\n",
      "  std_ssh: 0.0453692672359483\n",
      "  mean_sst: 15.956900367755182\n",
      "  std_sst: 5.987649544923141\n",
      "  N_t: 10\n",
      "  timesteps_range:\n",
      "  - 30\n",
      "  - 360\n",
      "  - 5\n",
      "  batch_size: 10\n",
      "  return_masks: false\n",
      "  cloud_rho: 0.5\n",
      "model:\n",
      "  Number_timesteps: 10\n",
      "  alpha0: 1\n",
      "  alpha1: 10\n",
      "  alpha2: 10\n",
      "  lr: 0.001\n",
      "  drop: 0.2\n",
      "  drop_path: 0.15\n",
      "  model_type: gSTA\n",
      "  multiprocessing: true\n",
      "  masked_loss: true\n",
      "training:\n",
      "  model_name: Simvip_in_nadirSSH_cloudSST_out_swotSSH_loss_gradmasked\n",
      "  num_epochs: 10\n",
      "  checkpoint_dir: checkpoints\n",
      "wandb:\n",
      "  project: swot_inpainting\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = compose(config_name=\"001_base_config\")\n",
    "print(OmegaConf.to_yaml(cfg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eaa7c376-1385-4fad-9e21-7254b18af58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(cfg):\n",
    "    # Configure\n",
    "    print(OmegaConf.to_yaml(cfg))\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_cpus = torch.get_num_threads() if torch.cuda.is_available() else 0\n",
    "    multiprocessing = torch.cuda.is_available()\n",
    "\n",
    "    # Prepare standards for transforms\n",
    "    standards = {\n",
    "                \"mean_ssh\":  cfg.data[\"mean_ssh\"], \"std_ssh\": cfg.data[\"std_ssh\"],\n",
    "                \"mean_sst\": cfg.data[\"mean_sst\"], \"std_sst\": cfg.data[\"std_sst\"]\n",
    "                }\n",
    "    # Load dataset\n",
    "    patch_coords = zarr.load(f\"{cfg.data.dataset_path}/{cfg.data.patch_coords_file}\")\n",
    "    full_dataset = ConcatDataset([\n",
    "        data_loaders.llc4320_dataset(\n",
    "            cfg.data.dataset_path, t, cfg.data.N_t, patch_coords,\n",
    "            cfg.data.infields, cfg.data.outfields, cfg.data.in_mask_list, cfg.data.out_mask_list,\n",
    "            cfg.data.in_transform_list, cfg.data.out_transform_list, standards=standards,\n",
    "            multiprocessing=multiprocessing, return_masks=cfg.data.return_masks\n",
    "        ) for t in cfg.data.timesteps_range\n",
    "    ])\n",
    "    train_len = int(0.7 * len(full_dataset))\n",
    "    val_len = int(0.2 * len(full_dataset))\n",
    "    test_len = len(full_dataset) - train_len - val_len\n",
    "    train_set, val_set, test_set = random_split(full_dataset, [train_len, val_len, test_len])\n",
    "    \n",
    "    # Instatiate data loaders\n",
    "    def worker_init_fn(worker_id):\n",
    "        _ = torch.utils.data.get_worker_info()\n",
    "    train_loader = DataLoader(train_set, batch_size=cfg.data.batch_size, shuffle=True, num_workers=n_cpus, worker_init_fn=worker_init_fn, persistent_workers=multiprocessing)\n",
    "    val_loader = DataLoader(val_set, batch_size=cfg.data.batch_size, shuffle=True, num_workers=n_cpus, worker_init_fn=worker_init_fn, persistent_workers=multiprocessing)\n",
    "    test_loader = DataLoader(test_set, batch_size=cfg.data.batch_size, shuffle=False, num_workers=n_cpus, worker_init_fn=worker_init_fn, persistent_workers=multiprocessing)\n",
    "    \n",
    "    # Instantiate model\n",
    "    in_shape = (cfg.model.Number_timesteps, len(cfg.data.infields), 128, 128)\n",
    "    base_model = simvip_model.SimVP_Model_no_skip_sst(in_shape=in_shape, **cfg.model)\n",
    "    \n",
    "    # Train model\n",
    "    train_model(\n",
    "        model=base_model,\n",
    "        device=device,\n",
    "        model_name=cfg.training.model_name,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        num_epochs=cfg.training.num_epochs,\n",
    "        lr=cfg.model.lr,\n",
    "        alpha0=cfg.model.alpha0,\n",
    "        alpha1=cfg.model.alpha1,\n",
    "        alpha2=cfg.model.alpha2,\n",
    "        masked_loss=cfg.model.masked_loss,\n",
    "        wandb_config=cfg.wandb\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c0b37e5-28be-48ca-893f-8e1844885da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outdir: ./outputs_SimVip_July_10\n",
      "data:\n",
      "  dataset_path: /home/tm3076/scratch/pytorch_learning_tiles\n",
      "  patch_coords_file: x_y_coordinates_noland.zarr\n",
      "  infields:\n",
      "  - zarr_llc4320_SSH_tiles_4km_filtered\n",
      "  - zarr_llc4320_SST_tiles_4km\n",
      "  outfields:\n",
      "  - zarr_llc4320_SSH_tiles_4km_filtered\n",
      "  in_mask_list:\n",
      "  - nadir\n",
      "  - cloud_rho\n",
      "  out_mask_list:\n",
      "  - swot_central\n",
      "  in_transform_list:\n",
      "  - std_global_mean_ssh_norm\n",
      "  - std_global_mean_sst_norm\n",
      "  out_transform_list:\n",
      "  - std_global_mean_ssh_norm\n",
      "  mean_ssh: 0\n",
      "  std_ssh: 0.0453692672359483\n",
      "  mean_sst: 15.956900367755182\n",
      "  std_sst: 5.987649544923141\n",
      "  N_t: 10\n",
      "  timesteps_range:\n",
      "  - 30\n",
      "  - 360\n",
      "  - 5\n",
      "  batch_size: 10\n",
      "  return_masks: false\n",
      "  cloud_rho: 0.5\n",
      "model:\n",
      "  Number_timesteps: 10\n",
      "  alpha0: 1\n",
      "  alpha1: 10\n",
      "  alpha2: 10\n",
      "  lr: 0.001\n",
      "  drop: 0.2\n",
      "  drop_path: 0.15\n",
      "  model_type: gSTA\n",
      "  multiprocessing: true\n",
      "  masked_loss: true\n",
      "training:\n",
      "  model_name: Simvip_in_nadirSSH_cloudSST_out_swotSSH_loss_gradmasked\n",
      "  num_epochs: 10\n",
      "  checkpoint_dir: checkpoints\n",
      "wandb:\n",
      "  project: swot_inpainting\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 40\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     37\u001b[0m base_model \u001b[38;5;241m=\u001b[39m simvip_model\u001b[38;5;241m.\u001b[39mSimVP_Model_no_skip_sst(in_shape\u001b[38;5;241m=\u001b[39min_shape, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmasked_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_loss\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 50\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, device, model_name, train_loader, val_loader, test_loader, num_epochs, lr, alpha0, alpha1, alpha2, masked_loss, checkpoint_dir, wandb_config)\u001b[0m\n\u001b[1;32m     48\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     49\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 50\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m Training\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasked_loss\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext3/miniforge3/envs/swot_python12_pytorch/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/ext3/miniforge3/envs/swot_python12_pytorch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/ext3/miniforge3/envs/swot_python12_pytorch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/ext3/miniforge3/envs/swot_python12_pytorch/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/ext3/miniforge3/envs/swot_python12_pytorch/lib/python3.12/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m/ext3/miniforge3/envs/swot_python12_pytorch/lib/python3.12/site-packages/torch/utils/data/dataset.py:350\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     sample_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_sizes[dataset_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/projects/NYU_SWOT_project/Inpainting_Pytorch_gen/SWOT-inpainting-DL/src/data_loaders.py:106\u001b[0m, in \u001b[0;36mllc4320_dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_patch\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Warning] Failed to load patch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m — falling back to patch 065\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/NYU_SWOT_project/Inpainting_Pytorch_gen/SWOT-inpainting-DL/src/data_loaders.py:118\u001b[0m, in \u001b[0;36mllc4320_dataset._load_patch\u001b[0;34m(self, idx, patch_id)\u001b[0m\n\u001b[1;32m    116\u001b[0m     coords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m invars, in_masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_patch_fields(patch_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfields, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_transform_list, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_mask_list)\n\u001b[0;32m--> 118\u001b[0m outvars, out_masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_patch_fields\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_transform_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_mask_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m invar \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(invars, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    120\u001b[0m outvar \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(outvars, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/projects/NYU_SWOT_project/Inpainting_Pytorch_gen/SWOT-inpainting-DL/src/data_loaders.py:148\u001b[0m, in \u001b[0;36mllc4320_dataset._load_patch_fields\u001b[0;34m(self, patch_id, fields, transform_keys, mask_keys)\u001b[0m\n\u001b[1;32m    146\u001b[0m var \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;28mlist\u001b[39m(ds\u001b[38;5;241m.\u001b[39mdata_vars\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    147\u001b[0m var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms[transform_keys[i]](var)\n\u001b[0;32m--> 148\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_keys\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m variables\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mtensor(var\u001b[38;5;241m.\u001b[39mvalues) \u001b[38;5;241m*\u001b[39m mask)\n\u001b[1;32m    150\u001b[0m masks\u001b[38;5;241m.\u001b[39mappend(masks)\n",
      "File \u001b[0;32m~/projects/NYU_SWOT_project/Inpainting_Pytorch_gen/SWOT-inpainting-DL/src/data_loaders.py:162\u001b[0m, in \u001b[0;36mllc4320_dataset.get_mask\u001b[0;34m(self, mask_key, patch_ID)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(mask_key)\u001b[38;5;241m.\u001b[39mlower():\n\u001b[1;32m    161\u001b[0m         sampling\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_random_swot_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnadir\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(mask_key)\u001b[38;5;241m.\u001b[39mlower():\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_nadir_altimeter_mask(patch_ID)\n",
      "File \u001b[0;32m~/projects/NYU_SWOT_project/Inpainting_Pytorch_gen/SWOT-inpainting-DL/src/data_loaders.py:183\u001b[0m, in \u001b[0;36mllc4320_dataset.get_random_swot_mask\u001b[0;34m(self, version, sampling)\u001b[0m\n\u001b[1;32m    181\u001b[0m         m0 \u001b[38;5;241m=\u001b[39m interp_utils\u001b[38;5;241m.\u001b[39mgrid_everything(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker_generic_swath0, lat, lon, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN, L_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL_x, L_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL_y)\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m         m0 \u001b[38;5;241m=\u001b[39m \u001b[43minterp_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_everything\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworker_generic_swath1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mL_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mL_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     mask \u001b[38;5;241m=\u001b[39m (m0\u001b[38;5;241m.\u001b[39mssha\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m version \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/projects/NYU_SWOT_project/SWOT-data-analysis/src/interp_utils.py:254\u001b[0m, in \u001b[0;36mgrid_everything\u001b[0;34m(swath_data, lat0, lon0, n, L_x, L_y, trim_edges)\u001b[0m\n\u001b[1;32m    252\u001b[0m     lons \u001b[38;5;241m=\u001b[39m (swath_data\u001b[38;5;241m.\u001b[39mlongitude\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m360\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m180\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m360\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m180\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# Project latitude and longitude coordinates onto an ENU coordinate system\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m x, y, z \u001b[38;5;241m=\u001b[39m \u001b[43mll2xyz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Generate regular cartesian points for grid coordinates\u001b[39;00m\n\u001b[1;32m    256\u001b[0m x_c, y_c \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39mL_x \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, L_x \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, n), np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39mL_y \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, L_y \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, n)\n",
      "File \u001b[0;32m~/projects/NYU_SWOT_project/SWOT-data-analysis/src/interp_utils.py:123\u001b[0m, in \u001b[0;36mll2xyz\u001b[0;34m(lat, lon, alt, lat_org, lon_org, alt_org, transformer)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03mConverts geodetic latitude, longitude, and altitude to local ENU (East-North-Up) coordinates.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    Arrays representing the ENU coordinates relative to the origin.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Convert geodetic coordinates to ECEF  (https://en.wikipedia.org/wiki/Earth-centered,_Earth-fixed_coordinate_system)\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m x, y, z \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlon\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradians\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Convert the ENU origin's geodetic coordinates to ECEF.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m x_org, y_org, z_org \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mtransform(lon_org, lat_org, alt_org, radians\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/ext3/miniforge3/envs/swot_python12_pytorch/lib/python3.12/site-packages/pyproj/transformer.py:842\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self, xx, yy, zz, tt, radians, errcheck, direction, inplace)\u001b[0m\n\u001b[1;32m    840\u001b[0m     intime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# call pj_transform.  inx,iny,inz buffers modified in place.\u001b[39;00m\n\u001b[0;32m--> 842\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43minx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43miny\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miny\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43minz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mradians\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradians\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrcheck\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;66;03m# if inputs were lists, tuples or floats, convert back.\u001b[39;00m\n\u001b[1;32m    852\u001b[0m outx \u001b[38;5;241m=\u001b[39m _convertback(x_data_type, inx)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "run(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6adebe9d-0245-4e20-b148-b3033c4cc560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/tm3076/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login 8fae6c89c2e1019988b71df99e344b4cf2c37755"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97878d6-f838-40d1-8873-18e94fed2117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swot_python12_pytorch",
   "language": "python",
   "name": "swot_python12_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
